{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Virtual environment\n",
    "### MAC\n",
    "```\n",
    "<code>\n",
    "python -m venv openai-env\n",
    "source openai-env/bin/activate\n",
    "pip install --upgrade openai\n",
    "</code>\n",
    "```\n",
    "### WINDOWS\n",
    "```\n",
    "<code>\n",
    "python -m venv openai-env\n",
    "openai-env\\Scripts\\activate\n",
    "pip install --upgrade openai\n",
    "</code>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting requests>=2.20 (from openai)\n",
      "  Downloading requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from openai)\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting aiohttp (from openai)\n",
      "  Downloading aiohttp-3.8.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.20->openai)\n",
      "  Downloading charset_normalizer-3.3.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.20->openai)\n",
      "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1 (from requests>=2.20->openai)\n",
      "  Downloading urllib3-2.0.7-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.20->openai)\n",
      "  Downloading certifi-2023.7.22-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp->openai)\n",
      "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
      "  Downloading multidict-6.0.4-cp311-cp311-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
      "  Downloading yarl-1.9.2-cp311-cp311-macosx_11_0_arm64.whl (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.3/61.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
      "  Downloading frozenlist-1.4.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.8.6-cp311-cp311-macosx_11_0_arm64.whl (343 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m343.5/343.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading certifi-2023.7.22-py3-none-any.whl (158 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.3/158.3 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading charset_normalizer-3.3.1-cp311-cp311-macosx_11_0_arm64.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.8/116.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading frozenlist-1.4.0-cp311-cp311-macosx_11_0_arm64.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading urllib3-2.0.7-py3-none-any.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, tqdm, multidict, idna, frozenlist, charset-normalizer, certifi, attrs, async-timeout, yarl, requests, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.6 aiosignal-1.3.1 async-timeout-4.0.3 attrs-23.1.0 certifi-2023.7.22 charset-normalizer-3.3.1 frozenlist-1.4.0 idna-3.4 multidict-6.0.4 openai-0.28.1 requests-2.31.0 tqdm-4.66.1 urllib3-2.0.7 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"In coding realms where logic blooms,\\nResides a concept, woven in looms.\\nA dance of function's mystic play,\\nRecursive echoes, in code they sway.\\n\\nWith elegance and subtle grace,\\nRecursion enters the programmer's space.\\nA method, a function, calling its own,\\nUnraveling patterns, a path unknown.\\n\\nLike fractal beauty painting skies,\\nRepetition whispers in programmers' eyes.\\nIt's a loop that twists and turns and twirls,\\nA symphony of echoes, unfurls.\\n\\nImagine a mirror, reflecting a mirror,\\nA cycle of creation, clearer and clearer.\\nA problem dissected, with each iteration,\\nRecursion dances, a sweet dedication.\\n\\nAn invocation, where code's not confined,\\nUnfolding layers of thoughts intertwined.\\nBuilding upon itself, in a loop deep,\\nAs if dreaming a dream, while still asleep.\\n\\nThrough recursive paths, we navigate,\\nSolving puzzles, unlocking fate.\\nSubproblems solved, in steps so small,\\nRecursive nature holds us enthralled.\\n\\nIn Fibonacci's sequence, a mathematical quest,\\nRecursion unveils patterns, at its behest.\\nIn towers of Hanoi's shifting rings,\\nRecursion teases with enigmatic springs.\\n\\nIn search of truth, through recursive inquiry,\\nDividing the problem, till answers grow nigh.\\nA universe where problems are tamed,\\nRecursive mind, forever unchained.\\n\\nBut caution, my friend, for recursion's embrace,\\nCan lead to cycles, a treacherous chase.\\nWith endless loops and infinite fall,\\nThe programmer's nightmare, waits to enthrall.\\n\\nSo craft your code with utmost care,\\nFor recursion's beauty, beware and dare.\\nA power to conquer, problems profound,\\nIn programming realms, where wonders abound.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tunning\n",
    "\n",
    "[https://platform.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model](https://platform.openai.com/docs/guides/fine-tuning/create-a-fine-tuned-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-72XuT0e7yZjdknjxvUYpKAQx at 0x106ea2750> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-72XuT0e7yZjdknjxvUYpKAQx\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 5028,\n",
       "  \"created_at\": 1698608781,\n",
       "  \"status\": \"processed\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upload a training file\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.File.create(\n",
    "  file=open(\"mydata.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-QIR1V1NbIo3o3JWcFZc5NXr8 at 0x106ea2b10> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-QIR1V1NbIo3o3JWcFZc5NXr8\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1698608847,\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"organization_id\": \"org-W5M9BYZguXaa7MuMntvl6qSl\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"validating_files\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-72XuT0e7yZjdknjxvUYpKAQx\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": \"auto\"\n",
       "  },\n",
       "  \"trained_tokens\": null,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a fine-tuned model\n",
    "\n",
    "openai.FineTuningJob.create(training_file=\"file-72XuT0e7yZjdknjxvUYpKAQx\", model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-QIR1V1NbIo3o3JWcFZc5NXr8 at 0x106ea1310> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-QIR1V1NbIo3o3JWcFZc5NXr8\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1698608847,\n",
       "  \"finished_at\": 1698609196,\n",
       "  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal::8F68WWsT\",\n",
       "  \"organization_id\": \"org-W5M9BYZguXaa7MuMntvl6qSl\",\n",
       "  \"result_files\": [\n",
       "    \"file-e9wiZazB8avwJdY7fBzizpmX\"\n",
       "  ],\n",
       "  \"status\": \"succeeded\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-72XuT0e7yZjdknjxvUYpKAQx\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": 5\n",
       "  },\n",
       "  \"trained_tokens\": 6160,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "openai.FineTuningJob.retrieve(\"ftjob-QIR1V1NbIo3o3JWcFZc5NXr8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the fine tunned model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"El modelo 800LQLEDK65MVN tiene mayor potencia.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0613:personal::8F68WWsT\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Eres LED, un chatbot experto en iluminación\"},\n",
    "    {\"role\": \"user\", \"content\": \"Que producto tiene mas potencia, el 400LQLEDK65MVN o el 800LQLEDK65MVN?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Te sugiero el Reflector LED para Exterior 600 W, Luz Blanca, ya que cuenta con una alta potencia de 60,000 lumens.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0613:personal::8F68WWsT\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Eres LED, un chatbot experto en iluminación\"},\n",
    "    {\"role\": \"user\", \"content\": \"Que reflector me recomiendas si necesito una potencia cercana a los 60,000 lumens?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"Tenemos un reflector LED para exteriores de alta potencia de 1000 Watts. Es ideal para iluminar \\u00e1reas amplias. \\u00a1Su aplicaci\\u00f3n es ideal en estacionamientos o canchas deportivas!  Ade\\u00e1s, tiene un \\u00cdndice de Protecci\\u00f3n IP66 lo cual lo hace una luminaria de alta durabilidad en exteriores. \\nPuedes conocer m\\u00e1s en: https://www.ligtec.mx/lig00104x0m00-reflector-led-exterior-1000-w-6500-k-ip66-/p\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"ft:gpt-3.5-turbo-0613:personal::8F68WWsT\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"Eres LED, un chatbot experto en iluminación\"},\n",
    "    {\"role\": \"user\", \"content\": \"Cual es el reflector mas potente que tienes?\"}\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
